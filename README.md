# Awesome-Multimodal-Large-Language-Models
his is a repository for organizing articles related to Multimodal Large Language Models, Large Language Models, and Diffusion Models; Most papers are linked to **my reading notes**. Feel free to visit my [personal homepage](https://yfzhang114.github.io/) and contact me for collaboration and discussion.


### About Me :high_brightness: 
I'm a third-year Ph.D. student at the State Key Laboratory of Pattern Recognition, the University of Chinese Academy of Sciences, advised by Prof. [Tieniu Tan](http://people.ucas.ac.cn/~tantieniu). I have also spent time at Microsoft, advised by Prof. [Jingdong Wang](https://jingdongwang2017.github.io/), alibaba DAMO Academy, work with Prof. [Rong Jin](https://scholar.google.com/citations?user=CS5uNscAAAAJ&hl=zh-CN).


###  ğŸ”¥ Updated 2024-03-30
- Recent Modality Bridging papers of Multimodal Large Language Models have been updated.
- Our paper  [Debiasing Multimodal Large Language Models](https://arxiv.org/abs/2403.05262) has been released.  [[Code]](https://github.com/yfzhang114/LLaVA-Align) [[Reading Notes]](https://zhuanlan.zhihu.com/p/686461442)

# Table of Contents (ongoing)
* [Multimodal Large Language Models](#multimodal-large-language-models)
* [Diffusion Models](#diffusion-models)
* [Hallucination](#hallucination)
* [Alignment With Human Preference](#alignment-with-human-preference)
# Multimodal Large Language Models

1. [Chameleon: Mixed-Modal Early-Fusion Foundation Models](https://zhuanlan.zhihu.com/p/698911049)(meta: æ‰€æœ‰æ¨¡æ€éƒ½å›åˆ°token regreesionä»¥è¾¾åˆ°çµæ´»çš„ç†è§£/ç”Ÿæˆ)
2. [Flamingo: a Visual Language Model for Few-Shot Learning](https://zhuanlan.zhihu.com/p/688215018)(LLMæ¯ä¸€å±‚åˆ›å»ºé¢å¤–çš„blockå¤„ç†è§†è§‰ä¿¡æ¯)
3. [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://zhuanlan.zhihu.com/p/688215018)(q-formerèåˆè§†è§‰-è¯­è¨€ä¿¡æ¯)
4. [InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning](https://zhuanlan.zhihu.com/p/688215018)(qformer+instruction tuning)
5. [Visual Instruction Tuning](https://zhuanlan.zhihu.com/p/688215018)(MLPå¯¹é½ç‰¹å¾ï¼Œgpt4vç”Ÿæˆinstruction tuningæ•°æ®)
6. [Improved Baselines with Visual Instruction Tuning](https://zhuanlan.zhihu.com/p/688215018)(å¯¹äºllavaæ•°æ®é›†ä»¥åŠæ¨¡å‹å¤§å°çš„åˆæ­¥scaling)
7. [LLaVA-NeXT: Improved reasoning, OCR, and world knowledge](https://zhuanlan.zhihu.com/p/688215018)(åˆ†è¾¨ç‡*4ï¼Œæ•°æ®é›†æ›´å¤§)
8. [Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models](https://zhuanlan.zhihu.com/p/688215018)(ä¸€ç§ç«¯åˆ°ç«¯çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œé€šè¿‡è½»é‡çº§é€‚é…å™¨è¿æ¥å›¾åƒç¼–ç å™¨å’ŒLLM)
9. [MIMIC-IT: Multi-Modal In-Context Instruction Tuning](https://zhuanlan.zhihu.com/p/688215018)( MIMIC-ITåŒ…å«å¤šä¸ªå›¾ç‰‡æˆ–è§†é¢‘çš„è¾“å…¥æ•°æ®ï¼Œå¹¶æ”¯æŒå¤šæ¨¡æ€ä¸Šä¸‹æ–‡ä¿¡æ¯)
10. [LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding](https://zhuanlan.zhihu.com/p/688215018)(ä½¿ç”¨å…¬å¼€å¯ç”¨çš„OCRå·¥å…·åœ¨LAIONæ•°æ®é›†çš„422Kä¸ªæ–‡æœ¬ä¸°å¯Œçš„å›¾åƒä¸Šæ”¶é›†ç»“æœ)
11. [SVIT: Scaling up Visual Instruction Tuning](https://zhuanlan.zhihu.com/p/688215018)(ä¸€ä¸ªåŒ…å«420ä¸‡ä¸ªè§†è§‰æŒ‡å¯¼è°ƒæ•´æ•°æ®ç‚¹çš„æ•°æ®é›†)
12. [Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond](https://zhuanlan.zhihu.com/p/688215018)(cross attentionå¯¹é½ç‰¹å¾ï¼Œæ›´å¤§çš„ç¬¬ä¸€é˜¶æ®µè®­ç»ƒæ•°æ®)
13. [NExT-GPT: Any-to-Any Multimodal LLM](https://zhuanlan.zhihu.com/p/688215018)(ç«¯åˆ°ç«¯é€šç”¨çš„ä»»æ„å¯¹ä»»æ„MM-LLMï¼ˆMultimodal-Large Language Modelï¼‰ç³»ç»Ÿ)
14. [InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition](https://zhuanlan.zhihu.com/p/688215018)(è§†è§‰ä¿¡æ¯çš„å‹ç¼©é‡‡æ ·)
15. [CogVLM: Visual Expert for Pretrained Language Models](https://zhuanlan.zhihu.com/p/688215018)(åœ¨LLMçš„å„å±‚æ·»åŠ visual expertï¼Œå®ƒå…·æœ‰ç‹¬ç«‹çš„QKVå’ŒFFNç›¸å…³çš„å‚æ•°)
16. [OtterHD: A High-Resolution Multi-modality Model](https://zhuanlan.zhihu.com/p/688215018)(ä¸“é—¨è®¾è®¡ç”¨äºä»¥ç»†ç²’åº¦ç²¾åº¦è§£é‡Šé«˜åˆ†è¾¨ç‡è§†è§‰è¾“å…¥)
17. [Monkey : Image Resolution and Text Label Are Important Things for Large Multi-modal Models](https://zhuanlan.zhihu.com/p/688215018)(Monkeyæ¨¡å‹æå‡ºäº†ä¸€ç§æœ‰æ•ˆåœ°æé«˜è¾“å…¥åˆ†è¾¨ç‡çš„æ–¹æ³•ï¼Œæœ€é«˜å¯è¾¾ 896 x 1344 åƒç´ )
18. [LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models](https://zhuanlan.zhihu.com/p/688215018)(LLaMA-VIDèµ‹äºˆç°æœ‰æ¡†æ¶æ”¯æŒé•¿è¾¾ä¸€å°æ—¶çš„è§†é¢‘ï¼Œå¹¶é€šè¿‡é¢å¤–çš„ä¸Šä¸‹æ–‡æ ‡è®°æ¨åŠ¨äº†å®ƒä»¬çš„ä¸Šé™)
19. [MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](https://zhuanlan.zhihu.com/p/688215018)(è§£å†³äº†å¤šæ¨¡æ€ç¨€ç–å­¦ä¹ ä¸­çš„æ€§èƒ½ä¸‹é™é—®é¢˜)
20. [LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images](https://zhuanlan.zhihu.com/p/688215018)(é«˜æ•ˆå¤„ç†ä»»ä½•çºµæ¨ªæ¯”å’Œé«˜åˆ†è¾¨ç‡çš„å›¾åƒ)
21. [Yi-VL](https://zhuanlan.zhihu.com/p/688215018)(Yi-VLé‡‡ç”¨äº†LLaVAæ¶æ„ï¼Œç»è¿‡å…¨é¢çš„ä¸‰é˜¶æ®µè®­ç»ƒè¿‡ç¨‹ï¼Œä»¥å°†è§†è§‰ä¿¡æ¯ä¸Yi LLMçš„è¯­ä¹‰ç©ºé—´è‰¯å¥½å¯¹é½ï¼š)
22. [Mini-Gemini](https://zhuanlan.zhihu.com/p/693063778)(åŒè§†è§‰ç¼–ç å™¨ï¼Œä½¿ç”¨ä½åˆ†è¾¨ç‡çš„è§†è§‰ç¼–ç å™¨ç‰¹å¾ä½œä¸ºqueryï¼Œå°†é«˜åˆ†è¾¨ç‡ç‰¹å¾ä½œä¸ºkey å’Œvalueè¿›è¡Œtoken mining)

# Diffusion Models

# Hallucination

# Alignment With Human Preference

1. [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://zhuanlan.zhihu.com/p/693163438)(ç›´æ¥åå¥½ä¼˜åŒ–å…‹æœRLHFä¸ç¨³å®šçš„é—®é¢˜)
2. [KTO: Model Alignment as Prospect Theoretic Optimization](https://zhuanlan.zhihu.com/p/693163438)(ä¸éœ€è¦æˆå¯¹æ•°æ®çš„åå¥½ä¼˜åŒ–)
3. [Direct Preference Optimization with an Offset](https://zhuanlan.zhihu.com/p/693163438)(å¸¦åç§»çš„DPO, è¦æ±‚é¦–é€‰å“åº”å’Œä¸å—æ¬¢è¿å“åº”ä¹‹é—´çš„å¯èƒ½æ€§å·®å¼‚å¤§äºä¸€ä¸ªåç§»å€¼)
4. [Contrastive preference learning: Learning from human feedback without reinforcement learning](https://zhuanlan.zhihu.com/p/693163438)(å¯¹æ¯”åå¥½å­¦ä¹ ï¼ˆCPLï¼‰ç®—æ³•ï¼Œè¯¥ç®—æ³•ç”¨äºä»åå¥½ä¸­å­¦ä¹ æœ€ä¼˜ç­–ç•¥è€Œæ— éœ€å­¦ä¹ å¥–åŠ±å‡½æ•°ï¼Œä»è€Œé¿å…äº†å¯¹RLçš„éœ€æ±‚)
5. [Statistical Rejection Sampling Improves Preference Optimization](https://zhuanlan.zhihu.com/p/693163438)(ä½¿ç”¨æ‹’ç»æŠ½æ ·ä»ç›®æ ‡æœ€ä¼˜ç­–ç•¥ä¸­è·å–åå¥½æ•°æ®ï¼Œä»è€Œæ›´å‡†ç¡®åœ°ä¼°è®¡æœ€ä¼˜ç­–ç•¥)
6. [Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study](https://zhuanlan.zhihu.com/p/693163438)(åœ¨æ‰€æœ‰å®éªŒä¸­ï¼ŒPPOå§‹ç»ˆä¼˜äºDPOã€‚ç‰¹åˆ«æ˜¯åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„ä»£ç ç«èµ›ä»»åŠ¡ä¸­ï¼ŒPPOå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœ)
7. [Fine-tuning Aligned Language Models Compromises Safety](https://zhuanlan.zhihu.com/p/696707347)(å¾®è°ƒå¯¹é½çš„è¯­è¨€æ¨¡å‹ä¼šæŸå®³å®‰å…¨æ€§)
8. [ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline](https://mp.weixin.qq.com/s/lg7ueR9b-om0ecUEoT4x8w)(reward model, Rejective Fine-tuning, then DPOè¿­ä»£æå‡æ¨¡å‹æ•°å­¦æ€§èƒ½)
